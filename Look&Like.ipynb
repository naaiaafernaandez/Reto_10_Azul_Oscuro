{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ac5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier,ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, log_loss\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92945f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('Datos/Originales/Datos look&like/customers_data_2.csv',sep=';')\n",
    "df_products = pd.read_csv('Datos/Originales/Datos look&like/items_data.csv')\n",
    "df_interactions = pd.read_csv('Datos/Originales/Datos look&like/look_and_like_data_2.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8082ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_interactions.merge(df_users, on='user_id', how='left')\n",
    "df_full = df_full.merge(df_products, on='product_variant_id', how='left')\n",
    "target_map = {'true': 1, 'false': 0}\n",
    "df_full['target'] = df_full['response'].astype(str).str.lower().map(target_map)\n",
    "df_full = df_full.dropna(subset=['target'])\n",
    "df_full['occurred_on_'] = pd.to_datetime(df_full['occurred_on_'], errors='coerce')\n",
    "df_full['month'] = df_full['occurred_on_'].dt.month.fillna(-1).astype(int)\n",
    "mapa_precios = {'30-60': 45, '60-100': 80, '100+': 140}\n",
    "if 'prices' in df_full.columns:\n",
    "    user_budget = df_full['prices'].map(mapa_precios).fillna(45)\n",
    "    df_full['price_divergence'] = (df_full['current_price_eur'] - user_budget) / user_budget\n",
    "    df_full['price_divergence'] = df_full['price_divergence'].fillna(0)\n",
    "df_full.columns = [re.sub(r'[^\\w]', '_', col) for col in df_full.columns]\n",
    "cols_to_drop = ['user_id', 'product_variant_id', 'response', 'response_clean', \n",
    "                'place', 'occurred_on_', 'date_birth', 'target']\n",
    "features = [c for c in df_full.columns if c not in cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58065fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'product_variant_id', 'response', 'place', 'occurred_on_',\n",
       "       'user_market', 'frequency', 'newsletter_subscribed', 'dress_leisure',\n",
       "       'dress_work', 'fit_top', 'fit_bottom', 'body_shape', 'eyes', 'hair',\n",
       "       'size_top', 'size_bottom', 'size_footwear', 'size_bra', 'size_cup',\n",
       "       'height', 'weight', 'adventurous_x', 'prices', 'job', 'date_birth',\n",
       "       'age', 'is_mother', 'style_1', 'style_2', 'season', 'family', 'brand',\n",
       "       'model', 'color', 'size', 'adventurous_y', 'back_neckline', 'basic',\n",
       "       'bottom', 'chest_contour', 'chest_volume', 'closing',\n",
       "       'composition_detail', 'cover', 'cut', 'elasticated_lining', 'fabric',\n",
       "       'finishing', 'fit', 'heel_length', 'hip_contour', 'hips_volume',\n",
       "       'leg_height', 'light', 'long_cm', 'neck', 'neckline', 'print',\n",
       "       'rubber_waist', 'shot', 'shoulders_pad', 'size_feature', 'sizing',\n",
       "       'sleeve', 'sleeve_long', 'sleeve_long_cm', 'sole_length', 'style',\n",
       "       'thicknees', 'toecap', 'type_of_length', 'waist_contour', 'weather',\n",
       "       'current_price_eur', 'target', 'month', 'price_divergence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_full.to_csv(\"Datos/Transformados/look_like_full.csv\")\n",
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fe7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos listos. Train: (279409, 71) Test: (69853, 71)\n"
     ]
    }
   ],
   "source": [
    "X = df_full[features].copy()\n",
    "y = df_full['target'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "cat_cols = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train[num_cols] = imputer.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = imputer.transform(X_test[num_cols])\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_train[cat_cols] = X_train[cat_cols].fillna(\"Unknown\").astype(str)\n",
    "X_test[cat_cols] = X_test[cat_cols].fillna(\"Unknown\").astype(str)\n",
    "X_train[cat_cols] = encoder.fit_transform(X_train[cat_cols])\n",
    "X_test[cat_cols] = encoder.transform(X_test[cat_cols])\n",
    "print(f\"Datos listos. Train: {X_train.shape} Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d54de",
   "metadata": {},
   "source": [
    "**MODELOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "# XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [300, 500, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [6, 8, 10, 12],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],            \n",
    "    'reg_alpha': [0, 0.1, 1, 5],             \n",
    "    'reg_lambda': [1, 5, 10],               \n",
    "    'scale_pos_weight': [ratio]              \n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [300, 500, 700],\n",
    "    'max_depth': [15, 20, 25, 30, None],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# LightGBM\n",
    "lgbm_params = {\n",
    "    'n_estimators': [500, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 70, 100],         \n",
    "    'max_depth': [-1, 10, 15, 20],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# CatBoost\n",
    "cat_params = {\n",
    "    'iterations': [500, 800, 1000],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'depth': [6, 8, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'border_count': [64, 128, 254],\n",
    "    'auto_class_weights': ['Balanced']\n",
    "}\n",
    "modelos_a_optimizar = [\n",
    "    (\"XGBoost\", XGBClassifier(n_jobs=-1, random_state=42, eval_metric='auc'), xgb_params),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_jobs=-1, random_state=42), rf_params),\n",
    "    (\"LightGBM\", LGBMClassifier(n_jobs=-1, random_state=42, verbose=-1), lgbm_params),\n",
    "    (\"CatBoost\", CatBoostClassifier(verbose=0, random_state=42, allow_writing_files=False), cat_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizando XGBoost\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Mejor AUC (CV): 0.8070\n",
      "Tiempo: 535.89s\n",
      "\n",
      "Optimizando Random Forest\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Mejor AUC (CV): 0.8074\n",
      "Tiempo: 2686.64s\n",
      "\n",
      "Optimizando LightGBM\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Mejor AUC (CV): 0.8024\n",
      "Tiempo: 451.44s\n",
      "\n",
      "Optimizando CatBoost\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Mejor AUC (CV): 0.8025\n",
      "Tiempo: 1245.75s\n",
      "RESULTADOS FINALES EN TEST\n",
      "       Modelo      AUC\n",
      "      XGBoost 0.819682\n",
      "Random Forest 0.815550\n",
      "     LightGBM 0.813532\n",
      "     CatBoost 0.809855\n",
      "EL MEJOR MODELO OPTIMIZADO ES: **XGBoost**\n",
      "   AUC Score: 0.81968\n",
      "   Configuración Ganadora:\n",
      "{'subsample': 0.8, 'scale_pos_weight': np.float64(1.772932524835505), 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 800, 'max_depth': 12, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "mejores_resultados = []\n",
    "for nombre, modelo, params in modelos_a_optimizar:\n",
    "    print(f\"\\nOptimizando {nombre}\")\n",
    "    start = time.time()\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=modelo,\n",
    "        param_distributions=params,\n",
    "        n_iter=15,               \n",
    "        scoring='roc_auc',       \n",
    "        cv=3,                \n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42)\n",
    "    search.fit(X_train, y_train)\n",
    "    best_auc = search.best_score_\n",
    "    best_params = search.best_params_\n",
    "    best_estimator = search.best_estimator_\n",
    "    tiempo = time.time() - start\n",
    "    print(f\"Mejor AUC (CV): {best_auc:.4f}\")\n",
    "    print(f\"Tiempo: {tiempo:.2f}s\")\n",
    "    mejores_resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'Best_AUC_CV': best_auc,\n",
    "        'Best_Params': best_params,\n",
    "        'Estimator': best_estimator})\n",
    "    \n",
    "print(\"RESULTADOS FINALES EN TEST\")\n",
    "tabla_final = []\n",
    "for item in mejores_resultados:\n",
    "    modelo_opt = item['Estimator']\n",
    "    nombre = item['Modelo']\n",
    "    y_prob = modelo_opt.predict_proba(X_test)[:, 1]\n",
    "    y_pred = modelo_opt.predict(X_test)\n",
    "    auc_final = roc_auc_score(y_test, y_prob)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0) # zero_division evita errores si no predice nada\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    ll = log_loss(y_test, y_prob)\n",
    "    tabla_final.append({\n",
    "        'Modelo': nombre,'AUC': auc_final,\n",
    "        'Accuracy': acc,'F1-Score': f1,\n",
    "        'Precision': prec,'Recall': rec,\n",
    "        'Log Loss': ll,'Mejores Parámetros': item['Best_Params'],\n",
    "        'Estimator': modelo_opt})\n",
    "df_res = pd.DataFrame(tabla_final).sort_values(by='AUC', ascending=False)\n",
    "print(df_res[['Modelo', 'AUC']].to_string(index=False))\n",
    "ganador = df_res.iloc[0]\n",
    "print(f\"EL MEJOR MODELO OPTIMIZADO ES: **{ganador['Modelo']}**\")\n",
    "print(f\"   AUC Score: {ganador['AUC']:.5f}\")\n",
    "print(\"   Configuración Ganadora:\")\n",
    "print(ganador['Mejores Parámetros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ea0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modelos\\\\modelo_looklike.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umbral_final = float(ganador['Mejores Parámetros'].split('Threshold: ')[1].split(' ')[0]) if 'Threshold:' in str(ganador['Mejores Parámetros']) else 0.5\n",
    "artifacts = {\n",
    "    'model': ganador['Estimator'],\n",
    "    'threshold': umbral_final,\n",
    "    'encoder': encoder,\n",
    "    'imputer': imputer,\n",
    "    'features': features, \n",
    "    'num_cols': num_cols, \n",
    "    'cat_cols': cat_cols, 'input_dtypes': X_train.dtypes.to_dict(),\n",
    "    'metrics': {'auc': ganador['AUC'], 'f1': ganador['F1-Score'],\n",
    "        'Accuracy': ganador['Accuracy'],'Precision': ganador['Precision'],\n",
    "        'Recall': ganador['Recall'],'Log Loss': ganador['Log Loss']}}\n",
    "ruta_archivo = os.path.join('Modelos', 'modelo_looklike.pkl')\n",
    "os.makedirs('Modelos', exist_ok=True)\n",
    "joblib.dump(artifacts, ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efc220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AUC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Log Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Mejores Parámetros",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Estimator",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "cc3ecd9d-3528-4332-918b-105d71a05803",
       "rows": [
        [
         "0",
         "XGBoost",
         "0.8196817756965329",
         "0.7581778878501997",
         "0.660503255888737",
         "0.668919193975168",
         "0.6522964550831646",
         "0.49852940232179055",
         "{'subsample': 0.8, 'scale_pos_weight': np.float64(1.772932524835505), 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 800, 'max_depth': 12, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.6}",
         "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              feature_weights=None, gamma=0.2, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=12,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=800,\n              n_jobs=-1, num_parallel_tree=None, ...)"
        ],
        [
         "1",
         "Random Forest",
         "0.8155503497766785",
         "0.7591656764920619",
         "0.6286887235967952",
         "0.7079936369059455",
         "0.5653606446746854",
         "0.5056304319110914",
         "{'n_estimators': 700, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'class_weight': 'balanced_subsample'}",
         "RandomForestClassifier(class_weight='balanced_subsample', min_samples_leaf=2,\n                       n_estimators=700, n_jobs=-1, random_state=42)"
        ],
        [
         "2",
         "LightGBM",
         "0.8135322185255798",
         "0.7432035846706655",
         "0.6632879077974246",
         "0.6291350639176726",
         "0.7013615973958953",
         "0.5159464254114379",
         "{'subsample': 0.8, 'reg_alpha': 1, 'num_leaves': 100, 'n_estimators': 1000, 'max_depth': 20, 'learning_rate': 0.1, 'colsample_bytree': 0.7, 'class_weight': 'balanced'}",
         "LGBMClassifier(class_weight='balanced', colsample_bytree=0.7, max_depth=20,\n               n_estimators=1000, n_jobs=-1, num_leaves=100, random_state=42,\n               reg_alpha=1, subsample=0.8, verbose=-1)"
        ],
        [
         "3",
         "CatBoost",
         "0.809854826362718",
         "0.7366183270582509",
         "0.661876056752187",
         "0.6162348995585367",
         "0.7148187844865229",
         "0.5286117111299488",
         "{'learning_rate': 0.05, 'l2_leaf_reg': 3, 'iterations': 800, 'depth': 10, 'border_count': 128, 'auto_class_weights': 'Balanced'}",
         "<catboost.core.CatBoostClassifier object at 0x000001C6CED6AD10>"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Mejores Parámetros</th>\n",
       "      <th>Estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.819682</td>\n",
       "      <td>0.758178</td>\n",
       "      <td>0.660503</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>0.652296</td>\n",
       "      <td>0.498529</td>\n",
       "      <td>{'subsample': 0.8, 'scale_pos_weight': 1.77293...</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.759166</td>\n",
       "      <td>0.628689</td>\n",
       "      <td>0.707994</td>\n",
       "      <td>0.565361</td>\n",
       "      <td>0.505630</td>\n",
       "      <td>{'n_estimators': 700, 'min_samples_split': 2, ...</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.813532</td>\n",
       "      <td>0.743204</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.629135</td>\n",
       "      <td>0.701362</td>\n",
       "      <td>0.515946</td>\n",
       "      <td>{'subsample': 0.8, 'reg_alpha': 1, 'num_leaves...</td>\n",
       "      <td>LGBMClassifier(class_weight='balanced', colsam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.736618</td>\n",
       "      <td>0.661876</td>\n",
       "      <td>0.616235</td>\n",
       "      <td>0.714819</td>\n",
       "      <td>0.528612</td>\n",
       "      <td>{'learning_rate': 0.05, 'l2_leaf_reg': 3, 'ite...</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Modelo       AUC  Accuracy  F1-Score  Precision    Recall  Log Loss  \\\n",
       "0        XGBoost  0.819682  0.758178  0.660503   0.668919  0.652296  0.498529   \n",
       "1  Random Forest  0.815550  0.759166  0.628689   0.707994  0.565361  0.505630   \n",
       "2       LightGBM  0.813532  0.743204  0.663288   0.629135  0.701362  0.515946   \n",
       "3       CatBoost  0.809855  0.736618  0.661876   0.616235  0.714819  0.528612   \n",
       "\n",
       "                                  Mejores Parámetros  \\\n",
       "0  {'subsample': 0.8, 'scale_pos_weight': 1.77293...   \n",
       "1  {'n_estimators': 700, 'min_samples_split': 2, ...   \n",
       "2  {'subsample': 0.8, 'reg_alpha': 1, 'num_leaves...   \n",
       "3  {'learning_rate': 0.05, 'l2_leaf_reg': 3, 'ite...   \n",
       "\n",
       "                                           Estimator  \n",
       "0  XGBClassifier(base_score=None, booster=None, c...  \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', m...  \n",
       "2  LGBMClassifier(class_weight='balanced', colsam...  \n",
       "3  <catboost.core.CatBoostClassifier object at 0x...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9443bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lande\\anaconda3\\envs\\ml_moda\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:06:08] WARNING: D:\\bld\\xgboost-split_1765326876395\\work\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\lande\\anaconda3\\envs\\ml_moda\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:10:19] WARNING: D:\\bld\\xgboost-split_1765326876395\\work\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\lande\\anaconda3\\envs\\ml_moda\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:11:49] WARNING: D:\\bld\\xgboost-split_1765326876395\\work\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\lande\\anaconda3\\envs\\ml_moda\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:13:15] WARNING: D:\\bld\\xgboost-split_1765326876395\\work\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\lande\\anaconda3\\envs\\ml_moda\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:14:40] WARNING: D:\\bld\\xgboost-split_1765326876395\\work\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\lande\\anaconda3\\envs\\ml_moda\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [21:16:03] WARNING: D:\\bld\\xgboost-split_1765326876395\\work\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Umbral encontrado: 0.33\n",
      "                      Modelo       AUC  Accuracy  F1-Score  Precision  \\\n",
      "4  Stacking (XGB+RF+LGB+KNN)  0.823082  0.740942  0.677157   0.614951   \n",
      "0                    XGBoost  0.819682  0.758178  0.660503   0.668919   \n",
      "1              Random Forest  0.815550  0.759166  0.628689   0.707994   \n",
      "2                   LightGBM  0.813532  0.743204  0.663288   0.629135   \n",
      "3                   CatBoost  0.809855  0.736618  0.661876   0.616235   \n",
      "\n",
      "     Recall  Log Loss                                 Mejores Parámetros  \\\n",
      "4  0.753364  0.489761                                    Threshold: 0.33   \n",
      "0  0.652296  0.498529  {'subsample': 0.8, 'scale_pos_weight': 1.77293...   \n",
      "1  0.565361  0.505630  {'n_estimators': 700, 'min_samples_split': 2, ...   \n",
      "2  0.701362  0.515946  {'subsample': 0.8, 'reg_alpha': 1, 'num_leaves...   \n",
      "3  0.714819  0.528612  {'learning_rate': 0.05, 'l2_leaf_reg': 3, 'ite...   \n",
      "\n",
      "                                           Estimator  \n",
      "4  StackingClassifier(cv=5,\\n                   e...  \n",
      "0  XGBClassifier(base_score=None, booster=None, c...  \n",
      "1  (DecisionTreeClassifier(max_features='sqrt', m...  \n",
      "2  LGBMClassifier(class_weight='balanced', colsam...  \n",
      "3  <catboost.core.CatBoostClassifier object at 0x...  \n"
     ]
    }
   ],
   "source": [
    "count_neg = len(y_train) - sum(y_train)\n",
    "count_pos = sum(y_train)\n",
    "scale_weight = count_neg / count_pos\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 1000,'max_depth': 20,\n",
    "    'learning_rate': 0.1,'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,'reg_alpha': 1,\n",
    "    'scale_pos_weight': scale_weight, \n",
    "    'n_jobs': -1,'random_state': 42,\n",
    "    'eval_metric': 'logloss','use_label_encoder': False}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': 700,'min_samples_split': 2,\n",
    "    'min_samples_leaf': 2,'max_features': 'sqrt',\n",
    "    'max_depth': None,'class_weight': 'balanced_subsample',\n",
    "    'n_jobs': -1,'random_state': 42}\n",
    "\n",
    "lgbm_params = {\n",
    "    'n_estimators': 1000,'max_depth': 20,\n",
    "    'learning_rate': 0.1,'num_leaves': 100,\n",
    "    'subsample': 0.8,'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 1,'class_weight': 'balanced',\n",
    "    'n_jobs': -1,'random_state': 42,'verbose': -1}\n",
    "\n",
    "estimators = [\n",
    "    ('xgboost', XGBClassifier(**xgb_params)),\n",
    "    ('lightgbm', LGBMClassifier(**lgbm_params)),\n",
    "    ('rf', RandomForestClassifier(**rf_params)),\n",
    "    ('knn', make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=15)))]\n",
    "\n",
    "clf_stacking = StackingClassifier(\n",
    "    estimators=estimators,final_estimator=LogisticRegression(C=1.0, random_state=42),\n",
    "    passthrough=False, cv=5,n_jobs=1)\n",
    "clf_stacking.fit(X_train, y_train)\n",
    "\n",
    "y_prob_stack = clf_stacking.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "f1_scores = []\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob_stack >= thresh).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_thresh, zero_division=0))\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_idx]\n",
    "y_pred_opt = (y_prob_stack >= best_thresh).astype(int)\n",
    "\n",
    "acc_stack = accuracy_score(y_test, y_pred_opt)\n",
    "prec_stack = precision_score(y_test, y_pred_opt, zero_division=0)\n",
    "rec_stack = recall_score(y_test, y_pred_opt, zero_division=0)\n",
    "f1_stack = f1_score(y_test, y_pred_opt, zero_division=0) \n",
    "auc_stack = roc_auc_score(y_test, y_prob_stack)\n",
    "ll_stack = log_loss(y_test, y_prob_stack)\n",
    "if 'tabla_final' not in locals(): tabla_final = []\n",
    "tabla_final.append({\n",
    "    'Modelo': 'Stacking (XGB+RF+LGB+KNN)','AUC': auc_stack,\n",
    "    'Accuracy': acc_stack,'F1-Score': f1_stack,\n",
    "    'Precision': prec_stack,'Recall': rec_stack,\n",
    "    'Log Loss': ll_stack,'Mejores Parámetros': f'Threshold: {best_thresh:.2f}','Estimator': clf_stacking})\n",
    "df_res = pd.DataFrame(tabla_final).sort_values(by='AUC', ascending=False)\n",
    "print(f\"Mejor Umbral encontrado: {best_thresh:.2f}\")\n",
    "print(df_res.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d34919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modelos\\\\modelo_Stacking.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = {\n",
    "    'model': clf_stacking,\n",
    "    'threshold': best_thresh,\n",
    "    'features': X_train.columns.tolist(),\n",
    "    'num_cols': num_cols, \n",
    "    'cat_cols': cat_cols,\n",
    "    'input_dtypes': X_train.dtypes.to_dict(),\n",
    "    'encoder': encoder,\n",
    "    'imputer': imputer,\n",
    "    'metrics': {\n",
    "        'AUC': auc_stack,'F1': f1_stack,\n",
    "        'Accuracy': acc_stack,'Precision': prec_stack,\n",
    "        'Recall': rec_stack,'Log Loss': ll_stack}\n",
    "}\n",
    "ruta_archivo = os.path.join('Modelos', 'modelo_Stacking.pkl')\n",
    "os.makedirs('Modelos', exist_ok=True)\n",
    "joblib.dump(artifacts, ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82db151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Umbral: 0.30\n",
      "                      Modelo       AUC  F1-Score    Recall\n",
      "4  Stacking (XGB+RF+LGB+KNN)  0.823082  0.677157  0.753364\n",
      "0                    XGBoost  0.819682  0.660503  0.652296\n",
      "1              Random Forest  0.815550  0.628689  0.565361\n",
      "2                   LightGBM  0.813532  0.663288  0.701362\n",
      "3                   CatBoost  0.809855  0.661876  0.714819\n",
      "5          Stacking (ET+HGB)  0.760134  0.619749  0.767139\n"
     ]
    }
   ],
   "source": [
    "estimators_diversos = [\n",
    "    # ExtraTrees\n",
    "    ('et', ExtraTreesClassifier(\n",
    "        n_estimators=300, max_depth=10, \n",
    "        min_samples_leaf=2, class_weight='balanced', \n",
    "        n_jobs=-1, random_state=42)),\n",
    "    \n",
    "    # HistGradientBoosting\n",
    "    ('hgb', HistGradientBoostingClassifier(\n",
    "        max_iter=200, learning_rate=0.05, \n",
    "        max_depth=10,class_weight='balanced', \n",
    "        random_state=42))]\n",
    "\n",
    "clf_stacking_div = StackingClassifier(\n",
    "    estimators=estimators_diversos,final_estimator=LogisticRegression(penalty='l2', C=1.0, random_state=42),\n",
    "    passthrough=False, cv=5,n_jobs=-1)\n",
    "\n",
    "clf_stacking_div.fit(X_train, y_train)\n",
    "y_prob_stack_div = clf_stacking_div.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "f1_scores_div = []\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob_stack_div >= thresh).astype(int)\n",
    "    f1_scores_div.append(f1_score(y_test, y_pred_thresh, zero_division=0))\n",
    "best_idx_div = np.argmax(f1_scores_div)\n",
    "best_thresh_div = thresholds[best_idx_div]\n",
    "y_pred_opt_div = (y_prob_stack_div >= best_thresh_div).astype(int)\n",
    "\n",
    "acc_div = accuracy_score(y_test, y_pred_opt_div)\n",
    "prec_div = precision_score(y_test, y_pred_opt_div, zero_division=0)\n",
    "rec_div = recall_score(y_test, y_pred_opt_div, zero_division=0)\n",
    "f1_div = f1_score(y_test, y_pred_opt_div, zero_division=0)\n",
    "auc_div = roc_auc_score(y_test, y_prob_stack_div)\n",
    "ll_div = log_loss(y_test, y_prob_stack_div)\n",
    "tabla_final.append({\n",
    "    'Modelo': 'Stacking (ET+HGB)',\n",
    "    'AUC': auc_div,'Accuracy': acc_div,\n",
    "    'F1-Score': f1_div,'Precision': prec_div,\n",
    "    'Recall': rec_div,'Log Loss': ll_div,\n",
    "    'Mejores Parámetros': f'Threshold: {best_thresh_div:.2f} | Diverse Stack','Estimator': clf_stacking_div})\n",
    "df_res = pd.DataFrame(tabla_final).sort_values(by='AUC', ascending=False)\n",
    "print(f\"Mejor Umbral: {best_thresh_div:.2f}\")\n",
    "print(df_res[['Modelo', 'AUC', 'F1-Score', 'Recall']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea0360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral óptimo: 0.32\n",
      "                   Modelo      AUC  F1-Score  Log Loss\n",
      "Stacking (XGB+RF+LGB+KNN) 0.823082  0.677157  0.489761\n",
      "                  XGBoost 0.819682  0.660503  0.498529\n",
      "            Random Forest 0.815550  0.628689  0.505630\n",
      "                 LightGBM 0.813532  0.663288  0.515946\n",
      "                 CatBoost 0.809855  0.661876  0.528612\n",
      "Stacking (LGB+ET+KNN+LOG) 0.788336  0.643457  0.524282\n",
      "        Stacking (ET+HGB) 0.760134  0.619749  0.549169\n"
     ]
    }
   ],
   "source": [
    "estimators_hybrid = [\n",
    "    ('lgbm', LGBMClassifier(\n",
    "        n_estimators=300, learning_rate=0.03,\n",
    "        num_leaves=31,class_weight='balanced', \n",
    "        random_state=42, verbose=-1)),\n",
    "    ('et', ExtraTreesClassifier(\n",
    "        n_estimators=200, max_depth=12, \n",
    "        min_samples_leaf=3, class_weight='balanced', \n",
    "        n_jobs=-1, random_state=42)),\n",
    "    ('knn', make_pipeline(\n",
    "        StandardScaler(), KNeighborsClassifier(n_neighbors=25, weights='distance'))),\n",
    "    ('logreg_base', make_pipeline(\n",
    "        StandardScaler(), LogisticRegression(C=0.5, class_weight='balanced', solver='liblinear', random_state=42)))]\n",
    "\n",
    "clf_stacking_hybrid = StackingClassifier(\n",
    "    estimators=estimators_hybrid,\n",
    "    final_estimator=LogisticRegression(C=1.0, penalty='l2', random_state=42),\n",
    "    passthrough=False, cv=5,n_jobs=-1)\n",
    "\n",
    "clf_stacking_hybrid.fit(X_train, y_train)\n",
    "y_prob_stack_hyb = clf_stacking_hybrid.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "f1_scores_hyb = []\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob_stack_hyb >= thresh).astype(int)\n",
    "    f1_scores_hyb.append(f1_score(y_test, y_pred_thresh, zero_division=0))\n",
    "best_idx_hyb = np.argmax(f1_scores_hyb)\n",
    "best_thresh_hyb = thresholds[best_idx_hyb]\n",
    "y_pred_opt_hyb = (y_prob_stack_hyb >= best_thresh_hyb).astype(int)\n",
    "\n",
    "acc_hyb = accuracy_score(y_test, y_pred_opt_hyb)\n",
    "prec_hyb = precision_score(y_test, y_pred_opt_hyb, zero_division=0)\n",
    "rec_hyb = recall_score(y_test, y_pred_opt_hyb, zero_division=0)\n",
    "f1_hyb = f1_score(y_test, y_pred_opt_hyb, zero_division=0)\n",
    "auc_hyb = roc_auc_score(y_test, y_prob_stack_hyb)\n",
    "ll_hyb = log_loss(y_test, y_prob_stack_hyb)\n",
    "tabla_final.append({\n",
    "    'Modelo': 'Stacking (LGB+ET+KNN+LOG)','AUC': auc_hyb,\n",
    "    'Accuracy': acc_hyb,'F1-Score': f1_hyb,\n",
    "    'Precision': prec_hyb,'Recall': rec_hyb,\n",
    "    'Log Loss': ll_hyb,'Mejores Parámetros': f'Threshold: {best_thresh_hyb:.2f} | Passthrough Enabled',\n",
    "    'Estimator': clf_stacking_hybrid})\n",
    "\n",
    "df_res = pd.DataFrame(tabla_final).sort_values(by='AUC', ascending=False)\n",
    "print(f\"Umbral óptimo: {best_thresh_hyb:.2f}\")\n",
    "print(df_res[['Modelo', 'AUC', 'F1-Score', 'Log Loss']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor Umbral: 0.34\n",
      "                      Modelo       AUC  Accuracy  F1-Score\n",
      "4  Stacking (XGB+RF+LGB+KNN)  0.823082  0.740942  0.677157\n",
      "0                    XGBoost  0.819682  0.758178  0.660503\n",
      "1              Random Forest  0.815550  0.759166  0.628689\n",
      "2                   LightGBM  0.813532  0.743204  0.663288\n",
      "3                   CatBoost  0.809855  0.736618  0.661876\n",
      "7      Stacking (XGB+RF+LGB)  0.794229  0.709075  0.648372\n",
      "6  Stacking (LGB+ET+KNN+LOG)  0.788336  0.702962  0.643457\n",
      "5          Stacking (ET+HGB)  0.760134  0.660516  0.619749\n"
     ]
    }
   ],
   "source": [
    "count_neg = len(y_train) - sum(y_train)\n",
    "count_pos = sum(y_train)\n",
    "scale_weight = count_neg / count_pos\n",
    "\n",
    "estimators_champions = [\n",
    "    ('xgboost', XGBClassifier(\n",
    "        n_estimators=300,max_depth=5, \n",
    "        learning_rate=0.05,scale_pos_weight=scale_weight, \n",
    "        use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        n_estimators=300,max_depth=15, \n",
    "        class_weight='balanced',random_state=42)),\n",
    "    ('lightgbm', LGBMClassifier(\n",
    "        n_estimators=300, learning_rate=0.04,\n",
    "        class_weight='balanced', random_state=42, verbose=-1))]\n",
    "\n",
    "meta_model = LogisticRegression(\n",
    "    C=0.1,solver='lbfgs',random_state=42)\n",
    "\n",
    "clf_stacking_champ = StackingClassifier(\n",
    "    estimators=estimators_champions,final_estimator=meta_model,\n",
    "    passthrough=False,cv=5,n_jobs=-1)\n",
    "\n",
    "clf_stacking_champ.fit(X_train, y_train)\n",
    "y_prob_stack_champ = clf_stacking_champ.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "f1_scores_champ = []\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob_stack_champ >= thresh).astype(int)\n",
    "    f1_scores_champ.append(f1_score(y_test, y_pred_thresh, zero_division=0))\n",
    "best_idx_champ = np.argmax(f1_scores_champ)\n",
    "best_thresh_champ = thresholds[best_idx_champ]\n",
    "y_pred_opt_champ = (y_prob_stack_champ >= best_thresh_champ).astype(int)\n",
    "\n",
    "acc_champ = accuracy_score(y_test, y_pred_opt_champ)\n",
    "prec_champ = precision_score(y_test, y_pred_opt_champ, zero_division=0)\n",
    "rec_champ = recall_score(y_test, y_pred_opt_champ, zero_division=0)\n",
    "f1_champ = f1_score(y_test, y_pred_opt_champ, zero_division=0)\n",
    "auc_champ = roc_auc_score(y_test, y_prob_stack_champ)\n",
    "ll_champ = log_loss(y_test, y_prob_stack_champ)\n",
    "tabla_final.append({\n",
    "    'Modelo': 'Stacking (XGB+RF+LGB)',\n",
    "    'AUC': auc_champ,'Accuracy': acc_champ,\n",
    "    'F1-Score': f1_champ,'Precision': prec_champ,\n",
    "    'Recall': rec_champ,'Log Loss': ll_champ,\n",
    "    'Mejores Parámetros': f'Threshold: {best_thresh_champ:.2f} | Top3 Models','Estimator': clf_stacking_champ})\n",
    "df_res = pd.DataFrame(tabla_final).sort_values(by='AUC', ascending=False)\n",
    "df_res.to_csv('Datos/Transformados/Resultado_Modelos.csv')\n",
    "print(f\"Mejor Umbral: {best_thresh_champ:.2f}\")\n",
    "print(df_res[['Modelo', 'AUC', 'Accuracy', 'F1-Score']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f812877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Modelo       AUC  Accuracy  F1-Score  Precision  \\\n",
      "4  Stacking (XGB+RF+LGB+KNN)  0.823082  0.740942  0.677157   0.614951   \n",
      "0                    XGBoost  0.819682  0.758178  0.660503   0.668919   \n",
      "1              Random Forest  0.815550  0.759166  0.628689   0.707994   \n",
      "2                   LightGBM  0.813532  0.743204  0.663288   0.629135   \n",
      "3                   CatBoost  0.809855  0.736618  0.661876   0.616235   \n",
      "7      Stacking (XGB+RF+LGB)  0.794229  0.709075  0.648372   0.574671   \n",
      "6  Stacking (LGB+ET+KNN+LOG)  0.788336  0.702962  0.643457   0.567295   \n",
      "5          Stacking (ET+HGB)  0.760134  0.660516  0.619749   0.519867   \n",
      "\n",
      "     Recall  Log Loss                                 Mejores Parámetros  \\\n",
      "4  0.753364  0.489761                                    Threshold: 0.33   \n",
      "0  0.652296  0.498529  {'subsample': 0.8, 'scale_pos_weight': 1.77293...   \n",
      "1  0.565361  0.505630  {'n_estimators': 700, 'min_samples_split': 2, ...   \n",
      "2  0.701362  0.515946  {'subsample': 0.8, 'reg_alpha': 1, 'num_leaves...   \n",
      "3  0.714819  0.528612  {'learning_rate': 0.05, 'l2_leaf_reg': 3, 'ite...   \n",
      "7  0.743758  0.517867                      Threshold: 0.34 | Top3 Models   \n",
      "6  0.743242  0.524282              Threshold: 0.32 | Passthrough Enabled   \n",
      "5  0.767139  0.549169                    Threshold: 0.30 | Diverse Stack   \n",
      "\n",
      "                                           Estimator  \n",
      "4  StackingClassifier(cv=5,\\n                   e...  \n",
      "0  XGBClassifier(base_score=None, booster=None, c...  \n",
      "1  (DecisionTreeClassifier(max_features='sqrt', m...  \n",
      "2  LGBMClassifier(class_weight='balanced', colsam...  \n",
      "3  <catboost.core.CatBoostClassifier object at 0x...  \n",
      "7  StackingClassifier(cv=5,\\n                   e...  \n",
      "6  StackingClassifier(cv=5,\\n                   e...  \n",
      "5  StackingClassifier(cv=5,\\n                   e...  \n"
     ]
    }
   ],
   "source": [
    "print(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7da147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMULADOR\n",
      "User: d897293cfa134d53a717521430782460\n",
      "Prod: 1ccd9fc6-07c4-4eee-9171-6f6430ae3abd\n",
      "--------------------------------------------------\n",
      "Probabilidad: 65.37%\n",
      "Resultado:    ❤️ LIKE\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "from reglas import *\n",
    "user_random = df_users['user_id'].sample(1).iloc[0]\n",
    "prod_random = df_products['product_variant_id'].sample(1).iloc[0]\n",
    "simular_match(df_users,df_products,user_random,prod_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Mining_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
